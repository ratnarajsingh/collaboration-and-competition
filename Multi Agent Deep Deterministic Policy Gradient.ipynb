{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and initiate the tennis environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment\n",
    "from agents.utils import OUNoise\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "states = env_info.vector_observations\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(scores):\n",
    "    # plot the scores\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, n_episodes=500, noise = 1, noise_reduction=0.9999, train_mode=True):\n",
    "    \"\"\"\n",
    "    This method defines the how the agent is trained.\n",
    "    agent : Instance of MADDPG class with appropriate hyperparameters\n",
    "    n_episodes : Gives the number on eposides to run. The training loop breaks if either number of episodes are exceeded or the criterai is met\n",
    "    noise, noise_reduction : Its the \n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores_one_episode = np.zeros(2)\n",
    "        # reset the noise\n",
    "        agent.reset()\n",
    "        while True:\n",
    "            actions = agent.act(states, noise=noise)              # select an action (for each agent)\n",
    "            \n",
    "            # Concatenate all states and actions taken by all agents\n",
    "            # from agent 0 point of view, concatenate state seen by agent 0, state seen by agent 1, action agent 0, action agent 1\n",
    "            # from agent 1 point of view, concatenate state seen by agent 1, state seen by agent 0, action agent 1, action agent 0\n",
    "                \n",
    "            env_info = env.step(np.clip(actions, -1, 1))[brain_name]              # send all actions to the environment\n",
    "            next_states = env_info.vector_observations                            # get next state (for each agent)\n",
    "            rewards = env_info.rewards                                            # get reward (for each agent)\n",
    "            # lets try to promote cooperation\n",
    "            common_rewards = np.array(rewards)\n",
    "            common_rewards.fill(np.sum(common_rewards))\n",
    "            dones = env_info.local_done                                           # see if episode finished\n",
    "            agent.step(states, actions, common_rewards, next_states, dones)       # learn\n",
    "            states = next_states                                                  # roll over states to next time step\n",
    "            \n",
    "            scores_one_episode += rewards\n",
    "            if np.any(dones):                                                     # exit loop if episode finished\n",
    "                break\n",
    "                \n",
    "        noise = max(noise * noise_reduction, 0.01)        \n",
    "        score = np.max(scores_one_episode)\n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        mean_100 = np.mean(scores_window)\n",
    "\n",
    "        if i_episode % 50 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.3f}\\tMax Score: {:.3f}\\tNoise: {:.3f}'.\n",
    "                      format(i_episode, \n",
    "                         mean_100, \n",
    "                         np.max(scores_window),\n",
    "                        noise))\n",
    "            agent.save(\"weights/eps_{}_avg_{}.pth\".format(i_episode, mean_100))\n",
    "            \n",
    "        if len(scores_window) >= 100 and np.mean(scores_window)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.3f}'.format(i_episode, mean_100))\n",
    "            agent.save(\"final_weights/final.pth\")\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent and train\n",
    "* The MADDPG is one version of the DDPG that uses two pairs of Actor-Critic networks, local and target. As per the algorithm, knowledge of the states is shared by the agents by augmenting the critic network's input by giving full state observations as seen by each agent.\n",
    "* The hyperparameters are set and the agent is initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: 0.006\tMax Score: 0.100\tNoise: 0.980\n",
      "Episode 100\tAverage Score: 0.003\tMax Score: 0.100\tNoise: 0.961\n",
      "Episode 150\tAverage Score: 0.000\tMax Score: 0.000\tNoise: 0.942\n",
      "Episode 200\tAverage Score: 0.000\tMax Score: 0.000\tNoise: 0.923\n",
      "Episode 250\tAverage Score: 0.001\tMax Score: 0.100\tNoise: 0.905\n",
      "Episode 300\tAverage Score: 0.001\tMax Score: 0.100\tNoise: 0.887\n",
      "Episode 350\tAverage Score: 0.002\tMax Score: 0.100\tNoise: 0.869\n",
      "Episode 400\tAverage Score: 0.023\tMax Score: 0.100\tNoise: 0.852\n",
      "Episode 450\tAverage Score: 0.028\tMax Score: 0.100\tNoise: 0.835\n",
      "Episode 500\tAverage Score: 0.012\tMax Score: 0.100\tNoise: 0.819\n",
      "Episode 550\tAverage Score: 0.013\tMax Score: 0.100\tNoise: 0.802\n",
      "Episode 600\tAverage Score: 0.014\tMax Score: 0.200\tNoise: 0.787\n",
      "Episode 650\tAverage Score: 0.019\tMax Score: 0.300\tNoise: 0.771\n",
      "Episode 700\tAverage Score: 0.025\tMax Score: 0.300\tNoise: 0.756\n",
      "Episode 750\tAverage Score: 0.021\tMax Score: 0.200\tNoise: 0.741\n",
      "Episode 800\tAverage Score: 0.016\tMax Score: 0.100\tNoise: 0.726\n",
      "Episode 850\tAverage Score: 0.012\tMax Score: 0.100\tNoise: 0.712\n",
      "Episode 900\tAverage Score: 0.010\tMax Score: 0.200\tNoise: 0.698\n",
      "Episode 950\tAverage Score: 0.012\tMax Score: 0.200\tNoise: 0.684\n",
      "Episode 1000\tAverage Score: 0.008\tMax Score: 0.200\tNoise: 0.670\n",
      "Episode 1050\tAverage Score: 0.001\tMax Score: 0.090\tNoise: 0.657\n",
      "Episode 1100\tAverage Score: 0.000\tMax Score: 0.000\tNoise: 0.644\n",
      "Episode 1150\tAverage Score: 0.000\tMax Score: 0.000\tNoise: 0.631\n",
      "Episode 1200\tAverage Score: 0.000\tMax Score: 0.000\tNoise: 0.619\n",
      "Episode 1250\tAverage Score: 0.003\tMax Score: 0.100\tNoise: 0.606\n",
      "Episode 1300\tAverage Score: 0.010\tMax Score: 0.200\tNoise: 0.594\n",
      "Episode 1350\tAverage Score: 0.019\tMax Score: 0.300\tNoise: 0.583\n",
      "Episode 1400\tAverage Score: 0.024\tMax Score: 0.300\tNoise: 0.571\n",
      "Episode 1450\tAverage Score: 0.025\tMax Score: 0.200\tNoise: 0.560\n",
      "Episode 1500\tAverage Score: 0.029\tMax Score: 0.200\tNoise: 0.549\n",
      "Episode 1550\tAverage Score: 0.043\tMax Score: 0.200\tNoise: 0.538\n",
      "Episode 1600\tAverage Score: 0.055\tMax Score: 0.300\tNoise: 0.527\n",
      "Episode 1650\tAverage Score: 0.056\tMax Score: 0.300\tNoise: 0.517\n",
      "Episode 1700\tAverage Score: 0.052\tMax Score: 0.200\tNoise: 0.507\n",
      "Episode 1750\tAverage Score: 0.056\tMax Score: 0.190\tNoise: 0.497\n",
      "Episode 1800\tAverage Score: 0.066\tMax Score: 0.200\tNoise: 0.487\n",
      "Episode 1850\tAverage Score: 0.076\tMax Score: 0.300\tNoise: 0.477\n",
      "Episode 1900\tAverage Score: 0.089\tMax Score: 0.400\tNoise: 0.468\n",
      "Episode 1950\tAverage Score: 0.087\tMax Score: 0.400\tNoise: 0.458\n",
      "Episode 2000\tAverage Score: 0.083\tMax Score: 0.300\tNoise: 0.449\n",
      "Episode 2050\tAverage Score: 0.169\tMax Score: 1.100\tNoise: 0.440\n",
      "Episode 2100\tAverage Score: 0.177\tMax Score: 1.200\tNoise: 0.432\n",
      "Episode 2150\tAverage Score: 0.080\tMax Score: 1.200\tNoise: 0.423\n",
      "Episode 2200\tAverage Score: 0.082\tMax Score: 0.500\tNoise: 0.415\n",
      "Episode 2250\tAverage Score: 0.105\tMax Score: 0.500\tNoise: 0.406\n",
      "Episode 2300\tAverage Score: 0.145\tMax Score: 1.000\tNoise: 0.398\n",
      "\n",
      "Environment solved in 2341 episodes!\tAverage Score: 0.519\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents.utils import ReplayBuffer, SimpleNoise\n",
    "from agents.maddpg import MADDPG\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "seed = 257\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "agent = MADDPG(states.shape[1], action_size, states.shape[0], device,seed=seed,\n",
    "               GRADIENT_CLIP = 3,\n",
    "               ACTIVATION = F.relu,\n",
    "               TAU=1e-3,\n",
    "               UPDATE_EVERY=8,\n",
    "               TRANSFER_EVERY=2,\n",
    "               UPDATE_LOOP=12,\n",
    "               ADD_NOISE_EVERY=1,\n",
    "               BOOTSTRAP_SIZE=4,\n",
    "               LR_CRITIC = 3e-4,\n",
    "               LR_ACTOR = 3e-4, \n",
    "               MEMORY_SIZE = 5e4,\n",
    "               BATCH_SIZE = 128\n",
    "              )\n",
    "scores = train(agent, n_episodes=60000, noise = 1, noise_reduction = 0.9996, train_mode=True)\n",
    "plot_result(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue the training with small noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = train(agent, n_episodes=2000, noise = 0.02, noise_reduction = 0.99996, train_mode=True)\n",
    "# plot_result(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time :1601.7732453346252\n"
     ]
    }
   ],
   "source": [
    "total_time = time() - start\n",
    "print(\"Total time :{}\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
